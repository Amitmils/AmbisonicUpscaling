{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Name: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sound_field import SoundField,SoundFieldDataset,divide_to_subbands,divide_to_time_windows\n",
    "from signal_info import signal_info\n",
    "from optimizer import optimizer\n",
    "from optimizer_v2 import optimizer_v2\n",
    "from DoA_est import DoA_via_bands\n",
    "import utils\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import gc\n",
    "import os\n",
    "from collections import defaultdict,Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "LEBEDEV = 'lebedev'\n",
    "POINTS_162 = '162_points'\n",
    "SQP_OPT_METHOD = \"SQP\"\n",
    "GD_DEEP_OPT_METHOD = \"GD_Deep\"\n",
    "GD_OPT_METHOD = \"GD_lagrange_multi\" #GD_Deep GD_lagrange_multi\n",
    "SLS_OPT_METHOD = \"SLS\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda:0\")\n",
    "    print(\"Device Name:\", torch.cuda.get_device_name(DEVICE))\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"Device Name: CPU\")\n",
    "torch.set_grad_enabled(False)\n",
    "torch.cuda.empty_cache()  # Free up unused memory on GPU\n",
    "gc.collect()  # Clean up unused memory on CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = torch.load(r\"data\\WSJ0\\Dataset_03_01_25.pt\",weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    return batch  # Returns a list of custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SoundFieldDataset(data_set['train'])\n",
    "val_set = SoundFieldDataset(data_set['validation'])\n",
    "test_set = SoundFieldDataset(data_set['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_epochs = 100\n",
    "\n",
    "down_sample = 1\n",
    "num_bins = 45\n",
    "\n",
    "window_length = 1024\n",
    "max_num_windows = int(1e10)\n",
    "\n",
    "mask = None\n",
    "\n",
    "train_data_loader = DataLoader(train_set, batch_size=batch_size,collate_fn=custom_collate_fn, shuffle=True)\n",
    "val_data_loader = DataLoader(val_set, batch_size=len(val_set),collate_fn=custom_collate_fn, shuffle=True)\n",
    "test_data_loader = DataLoader(test_set, batch_size=len(test_set),collate_fn=custom_collate_fn, shuffle=True)\n",
    "\n",
    "Y_p = utils.create_sh_matrix(train_set.input_order, zen=train_set[0].P_th, azi=train_set[0].P_ph).to(DEVICE)\n",
    "opt_model = optimizer_v2(Y_p=Y_p,alpha=0.01,num_iters=5,device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 162])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 23.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 cuda:0\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 66.83 GiB. GPU 0 has a total capacity of 15.99 GiB of which 11.81 GiB is free. Of the allocated memory 270.53 MiB is allocated by PyTorch, and 2.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m curr_sound_field\u001b[38;5;241m.\u001b[39mwindow_length \u001b[38;5;241m=\u001b[39m window_length\n\u001b[0;32m      9\u001b[0m curr_sound_field\u001b[38;5;241m.\u001b[39mnum_windows \u001b[38;5;241m=\u001b[39m curr_sound_field\u001b[38;5;241m.\u001b[39mwindowed_anm_t\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m est_upscaled_subbands \u001b[38;5;241m=\u001b[39m \u001b[43mopt_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr_sound_field\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m gt_upscale_subbands \u001b[38;5;241m=\u001b[39m divide_to_subbands(anm_t\u001b[38;5;241m=\u001b[39mcurr_sound_field\u001b[38;5;241m.\u001b[39mgt_anm_t_upscaled, num_bins\u001b[38;5;241m=\u001b[39mnum_bins, downsample\u001b[38;5;241m=\u001b[39mdown_sample,sr\u001b[38;5;241m=\u001b[39mcurr_sound_field\u001b[38;5;241m.\u001b[39msr)\n\u001b[0;32m     13\u001b[0m gt_upscale_subbands_windowed \u001b[38;5;241m=\u001b[39m divide_to_time_windows(anm_t_subbands\u001b[38;5;241m=\u001b[39mgt_upscale_subbands,window_length\u001b[38;5;241m=\u001b[39mwindow_length, max_num_windows\u001b[38;5;241m=\u001b[39mmax_num_windows)\n",
      "File \u001b[1;32mc:\\Users\\amitmils\\Documents\\Repo\\AmbisonicUpscaling\\optimizer_v2.py:192\u001b[0m, in \u001b[0;36moptimizer_v2.forward\u001b[1;34m(self, sound_field, mask, preprocessing)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_processing(Bk, mask_matrix)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Note2Self : If we do optimization per band/window the post processing and opt need to come together\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# the rest is only when we are all down with the optimization\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m opt_Omega_K \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m sound_field\u001b[38;5;241m.\u001b[39msparse_dict_subbands, Dk_cpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_processing(\n\u001b[0;32m    194\u001b[0m     Bk, opt_Omega_K, D_prior\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    195\u001b[0m )\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# sum of all subbands\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\amitmils\\Documents\\Repo\\AmbisonicUpscaling\\optimizer_v2.py:117\u001b[0m, in \u001b[0;36moptimizer_v2.perform_optimization\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    116\u001b[0m     non_zero_indices_in_grid \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnonzero(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, :])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduced_Yp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_p_broadcast[:, :, :, non_zero_indices_in_grid]\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_windows, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_bins, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_SH_coeff, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    119\u001b[0m     )  \u001b[38;5;66;03m# TODO Currently assumes mask doesnt change over time\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     Omega_k \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mOmega_k0\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_dim_reconstruction_loss_per_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 66.83 GiB. GPU 0 has a total capacity of 15.99 GiB of which 11.81 GiB is free. Of the allocated memory 270.53 MiB is allocated by PyTorch, and 2.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch in train_data_loader:\n",
    "        curr_sound_field = batch[0]\n",
    "        curr_sound_field.a_nm_subbands = divide_to_subbands(anm_t=curr_sound_field.anm_t, num_bins=num_bins, downsample=down_sample, sr=curr_sound_field.sr)\n",
    "        curr_sound_field.windowed_anm_t = divide_to_time_windows(anm_t_subbands=curr_sound_field.a_nm_subbands,window_length=window_length, max_num_windows=max_num_windows)\n",
    "        \n",
    "        curr_sound_field.num_bins = num_bins\n",
    "        curr_sound_field.window_length = window_length\n",
    "        curr_sound_field.num_windows = curr_sound_field.windowed_anm_t.shape[0]\n",
    "        est_upscaled_subbands = opt_model.forward(curr_sound_field,mask)\n",
    "        \n",
    "        gt_upscale_subbands = divide_to_subbands(anm_t=curr_sound_field.gt_anm_t_upscaled, num_bins=num_bins, downsample=down_sample,sr=curr_sound_field.sr)\n",
    "        gt_upscale_subbands_windowed = divide_to_time_windows(anm_t_subbands=gt_upscale_subbands,window_length=window_length, max_num_windows=max_num_windows)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
