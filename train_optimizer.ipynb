{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Name: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sound_field import SoundField,SoundFieldDataset,divide_to_subbands,divide_to_time_windows\n",
    "from signal_info import signal_info\n",
    "from optimizer import optimizer\n",
    "from optimizer_v2 import optimizer_v2\n",
    "from DoA_est import DoA_via_bands\n",
    "import utils\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import gc\n",
    "import os\n",
    "from collections import defaultdict,Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "\n",
    "LEBEDEV = 'lebedev'\n",
    "POINTS_162 = '162_points'\n",
    "SQP_OPT_METHOD = \"SQP\"\n",
    "GD_DEEP_OPT_METHOD = \"GD_Deep\"\n",
    "GD_OPT_METHOD = \"GD_lagrange_multi\" #GD_Deep GD_lagrange_multi\n",
    "SLS_OPT_METHOD = \"SLS\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda:0\")\n",
    "    print(\"Device Name:\", torch.cuda.get_device_name(DEVICE))\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"Device Name: CPU\")\n",
    "torch.set_grad_enabled(False)\n",
    "torch.cuda.empty_cache()  # Free up unused memory on GPU\n",
    "gc.collect()  # Clean up unused memory on CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = torch.load(r\"data\\WSJ0\\Dataset_03_01_25.pt\",weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SoundFieldDataset(data_set['train'],DEVICE)\n",
    "val_set = SoundFieldDataset(data_set['validation'],DEVICE)\n",
    "test_set = SoundFieldDataset(data_set['test'],DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'device', 'input_order', 'upscaled_order', 'num_bins', 'window_length', 'max_num_windows', 'min_num_speakers', 'max_num_speakers', 'min_theta', 'max_theta', 'min_phi', 'max_phi', 'min_dist', 'sr', 'grid_type', 'P_th', 'P_ph'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_epochs = 100\n",
    "\n",
    "down_sample = 1\n",
    "num_bins = 45\n",
    "\n",
    "window_length = 1024\n",
    "max_num_windows = int(1e10)\n",
    "\n",
    "mask = None\n",
    "\n",
    "train_data_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_set, batch_size=len(val_set), shuffle=True)\n",
    "test_data_loader = DataLoader(test_set, batch_size=len(test_set), shuffle=True)\n",
    "\n",
    "Y_p = utils.create_sh_matrix(train_set.input_order, zen=train_set.P_th, azi=train_set.P_ph).to(DEVICE)\n",
    "Y_p_tag = utils.create_sh_matrix(3, zen=train_set.P_th, azi=train_set.P_ph).to(DEVICE) # upscaling matrix (TODO ADD UPSCALE ORDER TO DATASET INFO)\n",
    "opt_model = optimizer_v2(Y_p=Y_p,alpha=0.01,num_iters=5,device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch, num_bins, down_sample, window_length, max_num_windows,sr):\n",
    "    a_nmt_subbands = divide_to_subbands(batch[0], num_bins=num_bins, downsample=down_sample, sr=sr)\n",
    "    a_nmt_subbands_windowed = divide_to_time_windows(a_nmt_subbands,window_length=window_length, max_num_windows=max_num_windows)\n",
    "\n",
    "    gt_a_nmt_subbands = divide_to_subbands(batch[1], num_bins=num_bins, downsample=down_sample,sr=sr)\n",
    "    gt_a_nmt_subbands_windowed = divide_to_time_windows(anm_t_subbands=gt_a_nmt_subbands,window_length=window_length, max_num_windows=max_num_windows)\n",
    "    print(\"Finished Preprocessing\")\n",
    "    return a_nmt_subbands_windowed,gt_a_nmt_subbands_windowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for epoch in range(num_epochs):\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            next_preprocessed_batch = None\n",
    "            data_loader_iter = iter(train_data_loader)\n",
    "            curr_batch_idx = 0\n",
    "            while curr_batch_idx < len(train_data_loader):\n",
    "                # Preprocess the current batch on the CPU\n",
    "                if next_preprocessed_batch is None:\n",
    "                    start = time.time()\n",
    "                    low_order_subbands_windowed,high_order_subbands_windowed = preprocess_batch(next(data_loader_iter), num_bins, down_sample, window_length, max_num_windows,train_set.sr)\n",
    "                    print(\"Preprocessing Time:\",time.time()-start)\n",
    "                else:\n",
    "                    low_order_subbands_windowed,high_order_subbands_windowed = next_preprocessed_batch.result()\n",
    "\n",
    "                # Start preprocessing the next batch on the CPU\n",
    "                if curr_batch_idx < len(train_data_loader) - 1:\n",
    "                    next_batch = next(data_loader_iter)\n",
    "                    next_preprocessed_batch = executor.submit(preprocess_batch, next_batch, num_bins, down_sample, window_length, max_num_windows)\n",
    "                \n",
    "                print(\"Starting on GPU\")\n",
    "                est_high_order_subbands_windowed = opt_model.forward(low_order_subbands_windowed,mask)\n",
    "\n",
    "                curr_batch_idx += 1\n",
    "\n",
    "\n",
    "                # Do something with the preprocessed batch\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amitmils\\Documents\\Repo\\AmbisonicUpscaling\\sound_field.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  anm_t_subbands[:, :, coeff] = torch.tensor(erb_bank.subbands.T).clone()\n",
      "100%|██████████| 5/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "self must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m gt_a_nmt_subbands_windowed \u001b[38;5;241m=\u001b[39m divide_to_time_windows(anm_t_subbands\u001b[38;5;241m=\u001b[39mgt_a_nmt_subbands,window_length\u001b[38;5;241m=\u001b[39mwindow_length, max_num_windows\u001b[38;5;241m=\u001b[39mmax_num_windows)\n\u001b[0;32m      8\u001b[0m est_sparse_dict_subbands \u001b[38;5;241m=\u001b[39m opt_model\u001b[38;5;241m.\u001b[39mforward(a_nmt_subbands_windowed,mask)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m#change to (#Windows,#Bands,WindowLength,P)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m est_upscaled_subbands_windowed \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest_sparse_dict_subbands\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_p_tag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m a\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: self must be a matrix"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch in train_data_loader:\n",
    "        low_order_anmt,high_order_anmt = batch\n",
    "        a_nmt_subbands = divide_to_subbands(low_order_anmt, num_bins=num_bins, downsample=down_sample, sr=train_set.sr)\n",
    "        a_nmt_subbands_windowed = divide_to_time_windows(a_nmt_subbands,window_length=window_length, max_num_windows=max_num_windows)\n",
    "        gt_a_nmt_subbands = divide_to_subbands(high_order_anmt, num_bins=num_bins, downsample=down_sample,sr=train_set.sr)\n",
    "        gt_a_nmt_subbands_windowed = divide_to_time_windows(anm_t_subbands=gt_a_nmt_subbands,window_length=window_length, max_num_windows=max_num_windows)\n",
    "        est_sparse_dict_subbands = opt_model.forward(a_nmt_subbands_windowed,mask).permute(0,1,3,2) #change to (#Windows,#Bands,WindowLength,P)\n",
    "        est_upscaled_subbands_windowed = torch.matmul(est_sparse_dict_subbands,Y_p_tag.t())\n",
    "        a=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
